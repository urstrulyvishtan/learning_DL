{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sibi Learning Deep Learning and ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continous variable generation randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X          y\n",
      "0  0.976270   3.787390\n",
      "1  4.303787  12.508401\n",
      "2  2.055268   7.576197\n",
      "3  0.897664   3.259084\n",
      "4 -1.526904   1.434444\n",
      "(100,)\n",
      "[ 0.97627008  4.30378733  2.05526752  0.89766366 -1.52690401  2.91788226\n",
      " -1.24825577  7.83546002  9.27325521 -2.33116962  5.83450076  0.5778984\n",
      "  1.36089122  8.51193277 -8.57927884 -8.25741401 -9.59563205  6.65239691\n",
      "  5.56313502  7.40024296  9.57236684  5.98317128 -0.77041275  5.61058353\n",
      " -7.63451148  2.79842043 -7.13293425  8.89337834  0.43696644 -1.7067612\n",
      " -4.70888776  5.48467379 -0.87699336  1.36867898 -9.62420399  2.35270994\n",
      "  2.24191445  2.33867994  8.87496157  3.63640598 -2.80984199 -1.25936092\n",
      "  3.95262392 -8.79549057  3.33533431  3.41275739 -5.79234878 -7.42147405\n",
      " -3.69143298 -2.72578458  1.40393541 -1.22796973  9.76747676 -7.95910379\n",
      " -5.82246488 -6.77380964  3.06216651 -4.93416795 -0.67378454 -5.11148816\n",
      " -6.82060833 -7.79249718  3.12659179 -7.23634097 -6.06835277 -2.62549659\n",
      "  6.4198646  -8.05797448  6.75889815 -8.07803184  9.5291893  -0.62697597\n",
      "  9.53522176  2.09691039  4.78527159 -9.21624415 -4.34386075 -7.59606878\n",
      " -4.07719605 -7.62544562 -3.64033641 -1.71474011 -8.71705007  3.84944239\n",
      "  1.33202908 -4.69221018  0.46496107 -8.12118978  1.51892991  8.58592395\n",
      " -3.62862095  3.3482076  -7.36404275  4.32654408 -4.21187814 -6.33617276\n",
      "  1.7302587  -9.59784908  6.57880058 -9.90609048]\n"
     ]
    }
   ],
   "source": [
    "#set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "n_samples = 100\n",
    "\n",
    "#generate random predictor variables\n",
    "X = np.random.uniform(low = -10, high = 10, size = n_samples)\n",
    "\n",
    "#generate noise\n",
    "noise = np.random.normal(loc=0.0, scale=1.0, size=n_samples)\n",
    "\n",
    "#generate dependent variable\n",
    "y = 2*X + 3 + noise\n",
    "\n",
    "#convert to pandas dataframe\n",
    "data = pd.DataFrame({'X': X, 'y': y})\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical variable generation randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        X  y\n",
      "0  Medium  2\n",
      "1     Low  1\n",
      "2    High  3\n",
      "3     Low  1\n",
      "4    High  3\n"
     ]
    }
   ],
   "source": [
    "#generating a categorical variable independent variable\n",
    "x_1 = pd.Categorical(np.random.choice(['Low', 'Medium', 'High'], n_samples))\n",
    "\n",
    "#generating dependent variable y\n",
    "y_dict = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "\n",
    "y_1 = pd.Categorical([y_dict[x] for x in x_1])\n",
    "\n",
    "#convert to pandas dataframe\n",
    "data_1 = pd.DataFrame({'X': x_1, 'y': y_1})\n",
    "\n",
    "print(data_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical variables cannot be used in linear regression so have to convert to continous using one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X_High  X_Low  X_Medium  y\n",
      "0   False  False      True  2\n",
      "1   False   True     False  1\n",
      "2    True  False     False  3\n",
      "3   False   True     False  1\n",
      "4    True  False     False  3\n"
     ]
    }
   ],
   "source": [
    "#one hot encoding of independent variable x\n",
    "X_encoded = pd.get_dummies(data_1['X'], prefix='X', drop_first=False)\n",
    "\n",
    "#convert the dependent variable to integer\n",
    "y_encoded = data_1['y'].astype('int')\n",
    "\n",
    "data_encoded = pd.concat([X_encoded, y_encoded], axis=1)\n",
    "\n",
    "print(data_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now data is ready we have to do test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_categorical = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_categorical.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.7215701230124905e-31\n",
      "Mean Squared Error: 2.7215701230124905e-31\n",
      "R2 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "mae = mean_squared_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('Mean Absolute Error:', mae)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('R2 Score:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets try to do for continous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y, random_state=0)\n",
    "\n",
    "mode_continuous = LinearRegression().fit(X_train_1.reshape(-1, 1), y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = mode_continuous.predict(X_test_1.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.0934268926184856\n",
      "Mean Squared Error: 1.0934268926184856\n",
      "R2 Score: 0.9917428854927943\n"
     ]
    }
   ],
   "source": [
    "mae_1 = mean_squared_error(y_test_1, y_pred_1)\n",
    "mse_1 = mean_squared_error(y_test_1, y_pred_1)\n",
    "r2_1 = r2_score(y_test_1, y_pred_1)\n",
    "\n",
    "print('Mean Absolute Error:', mae_1)\n",
    "print('Mean Squared Error:', mse_1)\n",
    "print('R2 Score:', r2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Linear regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, learning_rate=0.001, n_iters=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        #init parameters\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        #gradient descent\n",
    "        for _ in range(self.n_iters):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "            dw = (1/n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1/n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.dot(X, self.weights) + self.bias\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

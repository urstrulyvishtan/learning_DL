{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sibi Learning Deep Learning and ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continous variable generation randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X          y\n",
      "0  0.976270   3.787390\n",
      "1  4.303787  12.508401\n",
      "2  2.055268   7.576197\n",
      "3  0.897664   3.259084\n",
      "4 -1.526904   1.434444\n"
     ]
    }
   ],
   "source": [
    "#set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "n_samples = 100\n",
    "\n",
    "#generate random predictor variables\n",
    "X = np.random.uniform(low = -10, high = 10, size = n_samples)\n",
    "\n",
    "#generate noise\n",
    "noise = np.random.normal(loc=0.0, scale=1.0, size=n_samples)\n",
    "\n",
    "#generate dependent variable\n",
    "y = 2*X + 3 + noise\n",
    "\n",
    "#convert to pandas dataframe\n",
    "data = pd.DataFrame({'X': X, 'y': y})\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical variable generation randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        X  y\n",
      "0     Low  1\n",
      "1  Medium  2\n",
      "2  Medium  2\n",
      "3  Medium  2\n",
      "4     Low  1\n"
     ]
    }
   ],
   "source": [
    "#generating a categorical variable independent variable\n",
    "x_1 = pd.Categorical(np.random.choice(['Low', 'Medium', 'High'], n_samples))\n",
    "\n",
    "#generating dependent variable y\n",
    "y_dict = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "\n",
    "y_1 = pd.Categorical([y_dict[x] for x in x_1])\n",
    "\n",
    "#convert to pandas dataframe\n",
    "data_1 = pd.DataFrame({'X': x_1, 'y': y_1})\n",
    "\n",
    "print(data_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical variables cannot be used in linear regression so have to convert to continous using one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X_High  X_Low  X_Medium  y\n",
      "0   False   True     False  1\n",
      "1   False  False      True  2\n",
      "2   False  False      True  2\n",
      "3   False  False      True  2\n",
      "4   False   True     False  1\n"
     ]
    }
   ],
   "source": [
    "#one hot encoding of independent variable x\n",
    "X_encoded = pd.get_dummies(data_1['X'], prefix='X', drop_first=False)\n",
    "\n",
    "#convert the dependent variable to integer\n",
    "y_encoded = data_1['y'].astype('int')\n",
    "\n",
    "data_encoded = pd.concat([X_encoded, y_encoded], axis=1)\n",
    "\n",
    "print(data_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now data is ready we have to do test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_categorical = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_categorical.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.7215701230124905e-31\n",
      "Mean Squared Error: 2.7215701230124905e-31\n",
      "R2 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "mae = mean_squared_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('Mean Absolute Error:', mae)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('R2 Score:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets try to do for continous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y, random_state=0)\n",
    "\n",
    "mode_continuous = LinearRegression().fit(X_train_1.reshape(-1, 1), y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = mode_continuous.predict(X_test_1.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.0934268926184856\n",
      "Mean Squared Error: 1.0934268926184856\n",
      "R2 Score: 0.9917428854927943\n"
     ]
    }
   ],
   "source": [
    "mae_1 = mean_squared_error(y_test_1, y_pred_1)\n",
    "mse_1 = mean_squared_error(y_test_1, y_pred_1)\n",
    "r2_1 = r2_score(y_test_1, y_pred_1)\n",
    "\n",
    "print('Mean Absolute Error:', mae_1)\n",
    "print('Mean Squared Error:', mse_1)\n",
    "print('R2 Score:', r2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Linear regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR:\n",
    "    def __init__(self, learning_rate=0.001, n_iters=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        #init parameters\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        #gradient descent\n",
    "        for _ in range(self.n_iters):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "            dw = (1/n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1/n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.dot(X, self.weights) + self.bias\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_model = LR()\n",
    "my_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = my_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.43887172, 1.15414374, 1.43887172, 1.15414374, 1.43887172,\n",
       "       1.43887172, 1.59579448, 1.43887172, 1.43887172, 1.15414374,\n",
       "       1.59579448, 1.59579448, 1.59579448, 1.59579448, 1.15414374,\n",
       "       1.15414374, 1.15414374, 1.59579448, 1.59579448, 1.15414374,\n",
       "       1.59579448, 1.43887172, 1.43887172, 1.15414374, 1.43887172])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.7006779426190163\n",
      "Mean Squared Error: 0.7519284758862012\n",
      "R2 Score: 0.9707354005665281\n"
     ]
    }
   ],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    corr_matrix = np.corrcoef(y_true, y_pred)\n",
    "    corr = corr_matrix[0, 1]\n",
    "    return corr**2\n",
    "\n",
    "print('Mean Absolute Error:', mae(y_test, y_pred))\n",
    "print('Mean Squared Error:', mse(y_test, y_pred))\n",
    "print('R2 Score:', r2(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
